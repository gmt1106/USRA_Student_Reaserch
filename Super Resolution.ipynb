{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-y53tpSG8Wg",
        "outputId": "c5c93c07-98e8-45b3-c1e5-572c55ab6da4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "*Uncomment if running on colab* \n",
        "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
        "\"\"\"\n",
        "# !git clone https://github.com/ubc-vision/juho-usra.git\n",
        "# !mv juho-usra/* ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03wzm-DZI2PS",
        "outputId": "2bdeb2e6-1879-4190-ffe6-5f3c75828f6e"
      },
      "outputs": [],
      "source": [
        "# pip install pytorch_model_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGTmWVEchK2J",
        "outputId": "9f57d0b0-e5a1-48a7-821c-67f964760ff7"
      },
      "outputs": [],
      "source": [
        "# pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install lpips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWol3dXZG8Wl"
      },
      "source": [
        "# Import lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNGCiVmIG8Wo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from einops import rearrange\n",
        "import os\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from pytorch_model_summary import summary\n",
        "# use tensorboard with pytorch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from models import *\n",
        "# currently can't install this package \n",
        "# from siren_pytorch import SirenNet\n",
        "from models.siren_pytorch import SirenNet\n",
        "# import lpips\n",
        "\n",
        "dtype = None\n",
        "if torch.cuda.is_available():\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "else:\n",
        "    dtype = torch.FloatTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW8Bso5MG8Wq"
      },
      "source": [
        "# Load image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "HmulR_SDG8Ws",
        "outputId": "b6dd93ec-45c6-41be-a918-475c44339aa0"
      },
      "outputs": [],
      "source": [
        "# Downsampler factor\n",
        "factor = 4 \n",
        "\n",
        "# set up original, HR, LR images for deep image prior \n",
        "path_to_image = 'data/sr/zebra_GT.png'\n",
        "img_orig_pil = Image.open(path_to_image)\n",
        "img_orig_np = np.array(img_orig_pil)\n",
        "img_orig_np = img_orig_np.transpose(2,0,1)\n",
        "img_orig_np = img_orig_np.astype(np.float32) / 255.\n",
        "# HR \n",
        "# we usually need the dimensions to be divisible by a power of two (32 in this case)\n",
        "new_size = (img_orig_pil.size[0] - img_orig_pil.size[0] % 32, img_orig_pil.size[1] - img_orig_pil.size[1] % 32)\n",
        "bbox = [(img_orig_pil.size[0] - new_size[0])/2, \n",
        "        (img_orig_pil.size[1] - new_size[1])/2, \n",
        "        (img_orig_pil.size[0] + new_size[0])/2,\n",
        "        (img_orig_pil.size[1] + new_size[1])/2,]\n",
        "img_HR_pil = img_orig_pil.crop(bbox)\n",
        "img_HR_np = np.array(img_HR_pil)\n",
        "img_HR_np = img_HR_np.transpose(2,0,1)\n",
        "img_HR_np = img_HR_np.astype(np.float32) / 255.\n",
        "# LR\n",
        "LR_size = [img_HR_pil.size[0] // factor, img_HR_pil.size[1] // factor]\n",
        "img_LR_pil = img_HR_pil.resize(LR_size, Image.ANTIALIAS)\n",
        "img_LR_np = np.array(img_LR_pil)\n",
        "img_LR_np = img_LR_np.transpose(2,0,1)\n",
        "img_LR_np = img_LR_np.astype(np.float32) / 255.\n",
        "\n",
        "net_input_width, net_input_height = img_HR_pil.size\n",
        "\n",
        "# show both HR and LR image\n",
        "plt.figure()\n",
        "plt.imshow(img_HR_pil)\n",
        "plt.figure()\n",
        "plt.imshow(img_LR_pil)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhQwJiaoG8Wt"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA7fiz2fG8Wt",
        "outputId": "ec1fb42c-351e-4dcf-e827-5f240c5da334"
      },
      "outputs": [],
      "source": [
        "# Setup input meshgrid \n",
        "tensors = [torch.linspace(-1, 1, steps = net_input_height), torch.linspace(-1, 1, steps = net_input_width)]\n",
        "net_input = torch.stack(torch.meshgrid(*tensors), dim=-1).type(dtype)\n",
        "net_input = rearrange(net_input, 'h w c -> () c h w', h = net_input_height, w = net_input_width)\n",
        "Deep_Image_Prior_net_input = net_input.clone().detach().requires_grad_()\n",
        "SIREN_net_input = net_input.clone().detach().requires_grad_()\n",
        "input_depth = 2\n",
        "\n",
        "# Setup Deep Image Prior \n",
        "pad = 'reflection'\n",
        "\n",
        "deepImagePriorNet = DeepImagePriorNet (\n",
        "            input_depth, 3, \n",
        "            channels_down = [128, 128, 128, 128, 128],\n",
        "            channels_up = [128, 128, 128, 128, 128],\n",
        "            channels_skip = [4, 4, 4, 4, 4],\n",
        "            kernel_size_down = [3, 3, 3, 3, 3],\n",
        "            kernel_size_up = [3, 3, 3, 3, 3],\n",
        "            upsample_mode = 'bilinear',\n",
        "            need_sigmoid=True, need_bias=True, pad=pad)\n",
        "\n",
        "\n",
        "# Setup SIREN\n",
        "sirenNet = SirenNet(\n",
        "    dim_in = input_depth,              # input dimension, ex. 2d coor\n",
        "    dim_hidden = 256,                  # hidden dimension\n",
        "    dim_out = 3,                       # output dimension, ex. rgb value\n",
        "    num_layers = 5,                    # number of layers\n",
        "    w0_initial = 30.)                  # different signals may require different omega_0 in the first layer - this is a hyperparameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3aeoT8QG8Wv"
      },
      "source": [
        "# Deep Image Prior train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "4c0rlf22G8Wv",
        "outputId": "044c9796-13b4-4e9e-ec04-32be2acb47b1"
      },
      "outputs": [],
      "source": [
        "# Train for Deep Image Prior\n",
        "def deepImagePriorTrain(Deep_Image_Prior_net_input):\n",
        "\n",
        "    LR = 0.01\n",
        "    num_iter = 25000\n",
        "    reg_noise_std = 0.03\n",
        "    Deep_Image_Prior_net_input_saved = Deep_Image_Prior_net_input.detach().clone()\n",
        "    noise = Deep_Image_Prior_net_input.detach().clone()\n",
        "    img_LR = torch.from_numpy(img_LR_np)[None, :].type(dtype)\n",
        "\n",
        "    # Create optimizier\n",
        "    parameters = deepImagePriorNet.parameters()\n",
        "    optimizer = torch.optim.Adam(parameters, lr=LR)\n",
        "\n",
        "    # Loss\n",
        "    loss_type = None #\"LPIPS\"\n",
        "    loss = None\n",
        "    if loss_type is \"LPIPS\":\n",
        "        # Learned Perceptual Image Patch Similarity (LPIPS) metric Loss   \n",
        "        loss = lpips.LPIPS(net='alex')\n",
        "    else:\n",
        "        loss = nn.MSELoss().type(dtype) \n",
        "\n",
        "    # tensorboard log directory \n",
        "    log_dir = None\n",
        "    if loss_type is \"LPIPS\":\n",
        "        log_dir = \"./logs/experiment/Deep_Image_Prior/super_resolution/LPIPS\"\n",
        "    else:\n",
        "        log_dir = \"./logs/experiment/Deep_Image_Prior/super_resolution/Adam\" \n",
        "\n",
        "    # Create summary writer\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # Create log directory and save directory if it does not exist\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(num_iter):\n",
        "\n",
        "        if reg_noise_std > 0:\n",
        "            Deep_Image_Prior_net_input = Deep_Image_Prior_net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "\n",
        "        # Apply the model to obtain scores (forward pass)\n",
        "        out_HR = deepImagePriorNet.forward(Deep_Image_Prior_net_input)\n",
        "        out_LR = nn.functional.interpolate(out_HR, scale_factor=1/factor, mode=\"bilinear\", antialias=True)\n",
        "\n",
        "        # Compute the loss \n",
        "        total_loss = loss(out_LR, img_LR)\n",
        "\n",
        "        # Compute gradients    \n",
        "        total_loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Zero the parameter gradients in the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Save the results\n",
        "        if i % 100 == 0:\n",
        "            # Write output image to tensorboard, using keywords `image_output`\n",
        "            writer.add_image(\"image_output\", out_HR, global_step=i, dataformats='NCHW')\n",
        "            if loss_type is \"LPIPS\":\n",
        "                # Write loss to tensorboard, using keywords `loss`\n",
        "                writer.add_scalar(\"LPIPS_loss\", total_loss, global_step=i)\n",
        "            else:\n",
        "                # Write loss to tensorboard, using keywords `loss`\n",
        "                writer.add_scalar(\"loss\", total_loss, global_step=i)\n",
        "            # Write PSNR of LR image \n",
        "            psnr_LR = peak_signal_noise_ratio(img_LR_np, out_LR.detach().cpu().numpy()[0])\n",
        "            writer.add_scalar(\"LR_PSNR\", psnr_LR, global_step=i)\n",
        "            # Write PSNR of HR image\n",
        "            psnr_HR = peak_signal_noise_ratio(img_HR_np, out_HR.detach().cpu().numpy()[0])\n",
        "            writer.add_scalar(\"HR_PSNR\", psnr_HR, global_step=i)\n",
        "            \n",
        "\n",
        "\n",
        "deepImagePriorTrain(Deep_Image_Prior_net_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coX8qCm8G8Wx"
      },
      "source": [
        "# SIREN train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdpqP2hTG8Wy"
      },
      "outputs": [],
      "source": [
        "# Train for SIREN\n",
        "def sirenTrain(SIREN_net_input):\n",
        "\n",
        "    LR = 0.01\n",
        "    num_iter = 25000\n",
        "    img_LR = torch.from_numpy(img_LR_np)[None, :].type(dtype)\n",
        "\n",
        "    # Create optimizier\n",
        "    parameters = deepImagePriorNet.parameters()\n",
        "    optimizer = torch.optim.Adam(parameters, lr=LR)\n",
        "\n",
        "    # Loss\n",
        "    loss_type = None #\"LPIPS\"\n",
        "    loss = None\n",
        "    if loss_type is \"LPIPS\":\n",
        "        # Learned Perceptual Image Patch Similarity (LPIPS) metric Loss   \n",
        "        loss = lpips.LPIPS(net='alex')\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "    else:\n",
        "        loss = nn.MSELoss().type(dtype)   \n",
        "\n",
        "    # tensorboard log directory \n",
        "    log_dir = None\n",
        "    if loss_type is \"LPIPS\":\n",
        "        log_dir = \"./logs/experiment/Siren/super_resolution/LPIPS\"\n",
        "    else:\n",
        "        log_dir = \"./logs/experiment/Siren/super_resolution/Adam\" \n",
        "\n",
        "    # Create summary writer\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    # Create log directory and save directory if it does not exist\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.makedirs(log_dir)\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(num_iter):\n",
        "\n",
        "        # Apply the model to obtain scores (forward pass)\n",
        "        out_HR = deepImagePriorNet.forward(SIREN_net_input)\n",
        "        out_LR = nn.functional.interpolate(out_HR, scale_factor=1/factor, mode=\"bilinear\", antialias=True)\n",
        "\n",
        "        # Compute the loss \n",
        "        total_loss = loss(out_LR, img_LR)\n",
        "\n",
        "        # Compute gradients    \n",
        "        total_loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Zero the parameter gradients in the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Save the results\n",
        "        if i % 100 == 0:\n",
        "            # Write output image to tensorboard, using keywords `image_output`\n",
        "            writer.add_image(\"image_output\", out_HR, global_step=i, dataformats='NCHW')\n",
        "            if loss_type is \"LPIPS\":\n",
        "                # Write loss to tensorboard, using keywords `loss`\n",
        "                writer.add_scalar(\"LPIPS_loss\", total_loss, global_step=i)\n",
        "            else:\n",
        "                # Write loss to tensorboard, using keywords `loss`\n",
        "                writer.add_scalar(\"loss\", total_loss, global_step=i)\n",
        "            # Write PSNR of LR image \n",
        "            psnr_LR = peak_signal_noise_ratio(img_LR_np, out_LR.detach().cpu().numpy()[0])\n",
        "            writer.add_scalar(\"LR_PSNR\", psnr_LR, global_step=i)\n",
        "            # Write PSNR of HR image\n",
        "            psnr_HR = peak_signal_noise_ratio(img_HR_np, out_HR.detach().cpu().numpy()[0])\n",
        "            writer.add_scalar(\"HR_PSNR\", psnr_HR, global_step=i)\n",
        "           \n",
        "\n",
        "\n",
        "sirenTrain(SIREN_net_input)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Super Resolution.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0ef3be7f0c0b8459529ee79533840b5b73ae5f82458da6e33134bc1d9f61d8b6"
    },
    "kernelspec": {
      "display_name": "Python ('cv_project')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
