{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "*Uncomment if running on colab* \n",
    "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
    "\"\"\"\n",
    "# !git clone https://github.com/ubc-vision/juho-usra.git\n",
    "# !mv juho-usra/* ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "import os\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from pytorch_model_summary import summary\n",
    "# use tensorboard with pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from models import *\n",
    "# currently can't install this package \n",
    "# from siren_pytorch import SirenNet\n",
    "from models.siren_pytorch import SirenNet\n",
    "\n",
    "dtype = None\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampler factor\n",
    "factor = 4 \n",
    "\n",
    "path_to_image = 'data/sr/zebra_GT.png'\n",
    "image = Image.open(path_to_image)\n",
    "image_width, image_height = image.size\n",
    "# HR \n",
    "img_HR_pil = image.copy()\n",
    "img_HR_np = np.array(img_HR_pil)\n",
    "img_HR_np = img_HR_np.transpose(2,0,1)\n",
    "img_HR_np = img_HR_np.astype(np.float32) / 255.\n",
    "# LR\n",
    "LR_size = [img_HR_pil.size[0] // factor, img_HR_pil.size[1] // factor]\n",
    "img_LR_pil = img_HR_pil.resize(LR_size, Image.ANTIALIAS)\n",
    "img_LR_np = np.array(img_LR_pil)\n",
    "img_LR_np = img_LR_np.transpose(2,0,1)\n",
    "img_LR_np = img_LR_np.astype(np.float32) / 255.\n",
    "\n",
    "# show both HR and LR image\n",
    "plt.figure()\n",
    "plt.imshow(img_HR_pil)\n",
    "plt.figure()\n",
    "plt.imshow(img_LR_pil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input meshgrid \n",
    "tensors = [torch.linspace(-1, 1, steps = image_height), torch.linspace(-1, 1, steps = image_width)]\n",
    "net_input = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
    "net_input = rearrange(net_input, 'h w c -> () c h w', h = image_height, w = image_width)\n",
    "Deep_Image_Prior_net_input =net_input.clone().detach().requires_grad_()\n",
    "SIREN_net_input = net_input.clone().detach().requires_grad_()\n",
    "input_depth = 2\n",
    "\n",
    "# Setup Deep Image Prior \n",
    "pad = 'reflection'\n",
    "\n",
    "deepImagePriorNet = DeepImagePriorNet (\n",
    "            input_depth, 3, \n",
    "            channels_down = [128, 128, 128, 128, 128],\n",
    "            channels_up = [128, 128, 128, 128, 128],\n",
    "            channels_skip = [4, 4, 4, 4, 4],\n",
    "            kernel_size_down = [3, 3, 3, 3, 3],\n",
    "            kernel_size_up = [3, 3, 3, 3, 3],\n",
    "            upsample_mode = 'bilinear',\n",
    "            need_sigmoid=True, need_bias=True, pad=pad)\n",
    "\n",
    "\n",
    "# Setup SIREN\n",
    "sirenNet = SirenNet(\n",
    "    dim_in = input_depth,              # input dimension, ex. 2d coor\n",
    "    dim_hidden = 256,                  # hidden dimension\n",
    "    dim_out = 3,                       # output dimension, ex. rgb value\n",
    "    num_layers = 5,                    # number of layers\n",
    "    w0_initial = 30.)                  # different signals may require different omega_0 in the first layer - this is a hyperparameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Image Prior train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for Deep Image Prior\n",
    "def deepImagePriorTrain(Deep_Image_Prior_net_input):\n",
    "\n",
    "    LR = 0.01\n",
    "    tv_weight = 0.0\n",
    "    num_iter = 2000\n",
    "    reg_noise_std = 0.03\n",
    "    Deep_Image_Prior_net_input_saved = Deep_Image_Prior_net_input.detach().clone()\n",
    "    noise = Deep_Image_Prior_net_input.detach().clone()\n",
    "    img_LR_var = torch.from_numpy(img_LR_np)[None, :].type(dtype)\n",
    "    psnr_history = []\n",
    "\n",
    "    # Create optimizier\n",
    "    parameters = deepImagePriorNet.parameters()\n",
    "    optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "\n",
    "    # Loss\n",
    "    loss = nn.MSELoss().type(dtype)    \n",
    "\n",
    "    # tensorboard log directory \n",
    "    log_dir = \"./logs/experiment/Deep_Image_Prior/super_resolution\"\n",
    "\n",
    "    # Create summary writer\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # Create log directory and save directory if it does not exist\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # Training loop\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        if reg_noise_std > 0:\n",
    "            Deep_Image_Prior_net_input = Deep_Image_Prior_net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "        # Apply the model to obtain scores (forward pass)\n",
    "        out_HR = deepImagePriorNet.forward(Deep_Image_Prior_net_input)\n",
    "        out_LR = nn.functional.interpolate(Deep_Image_Prior_net_input, antialias=True)\n",
    "\n",
    "        # Compute the loss \n",
    "        total_loss = loss(out_LR, img_LR_var)\n",
    "        if tv_weight > 0:\n",
    "            # Calculates TV loss\n",
    "            dh = torch.pow(out_HR[:,:,:,1:] - out_HR[:,:,:,:-1], 2)\n",
    "            dw = torch.pow(out_HR[:,:,1:,:] - out_HR[:,:,:-1,:], 2)\n",
    "            tv_loss = torch.sum(torch.pow(dh[:, :, :-1] + dw[:, :, :, :-1], 0.5))\n",
    "            total_loss += tv_weight * tv_loss\n",
    "        # Compute gradients    \n",
    "        total_loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        # Zero the parameter gradients in the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Log\n",
    "        psnr_LR = peak_signal_noise_ratio(img_LR_np, out_LR.detach().cpu().numpy()[0])\n",
    "        psnr_HR = peak_signal_noise_ratio(img_HR_np, out_HR.detach().cpu().numpy()[0])\n",
    "        print ('Iteration %05d    PSNR_LR %.3f   PSNR_HR %.3f' % (i, psnr_LR, psnr_HR), '\\r', end='')\n",
    "                            \n",
    "        # History\n",
    "        psnr_history.append([psnr_LR, psnr_HR])\n",
    "\n",
    "        # Image plot and monitor results\n",
    "        if i % 100 == 0:\n",
    "            # Write output image to tensorboard, using keywords `image_output`\n",
    "            writer.add_image(\"image_output\", out_HR, global_step=i, dataformats='NCHW')\n",
    "            # Write loss to tensorboard, using keywords `loss`\n",
    "            writer.add_scalar(\"loss\", total_loss, global_step=i)\n",
    "\n",
    "\n",
    "deepImagePriorTrain(Deep_Image_Prior_net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIREN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ef3be7f0c0b8459529ee79533840b5b73ae5f82458da6e33134bc1d9f61d8b6"
  },
  "kernelspec": {
   "display_name": "Python ('cv_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
